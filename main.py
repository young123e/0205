import streamlit as st
import re 
import urllib.request
import urllib.parse
import requests as rq
from bs4 import BeautifulSoup
import json
import pickle
import numpy as np
import pandas as pd
from PIL import Image
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from streamlit_lottie import st_lottie
import platform
import os
import urllib.error
from typing import Dict, List, Optional, Tuple

# --- [1. ì„¤ì • ë° ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜] ---
st.set_page_config(page_title="ğŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ ì‹œê°í™”")

STOPWORDS_FILE = './resources/user_stopwords.json'

def load_user_stopwords():
    if os.path.exists(STOPWORDS_FILE):
        try:
            with open(STOPWORDS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except: return set()
    return set()

def save_user_stopwords(stopwords_set):
    if not os.path.exists('./resources'):
        os.makedirs('./resources')
    with open(STOPWORDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(sorted(stopwords_set)), f, ensure_ascii=False)

def get_naver_news(keyword, display, start):
    client_id = st.session_state.get('client_id')
    client_secret = st.session_state.get('client_secret')
    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display={display}&start={start}"
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            return json.loads(response.read().decode('utf-8'))['items']
    except urllib.error.HTTPError as e:
        if e.code == 401:
            st.error("âŒ API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. Client IDì™€ Secretì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif e.code == 403:
            st.error("âŒ API ê¶Œí•œì´ ì—†ê±°ë‚˜ í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error(f"âŒ API ì˜¤ë¥˜ ë°œìƒ: {e.code}")
        return None # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  Noneì„ ë°˜í™˜í•˜ì—¬ ì—ëŸ¬ì„ì„ í‘œì‹œ
    except Exception as e:
        st.error(f"âŒ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def cleanText(text):
    text = re.sub(r'\d|[a-zA-Z]|\W',' ', text)
    return re.sub(r'\s+',' ', text)

def cleanHtml(text):
    text = re.sub(r'<[^>]+>', '', text)
    for ent, char in [('&quot;', '"'), ('&apos;', "'"), ('&amp;', '&'), ('&lt;', '<'), ('&gt;', '>')]:
        text = text.replace(ent, char)
    return text

@st.cache_resource
def getTokenizer():
    try:
        with open('./resources/my_tokenizer3.model','rb') as f:
            return pickle.load(f)
    except: return None

def get_font_path() -> Optional[str]:
    # 1. ë¨¼ì € resources í´ë”ì— ì§ì ‘ ì—…ë¡œë“œí•œ í°íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
    local_font = './resources/NanumGothic-Regular.ttf' # íŒŒì¼ëª…ì— ë§ì¶° ìˆ˜ì •
    if os.path.exists(local_font):
        return local_font
    
    # 2. ì—†ì„ ê²½ìš° ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„ (ê¸°ì¡´ ë¡œì§)
    system = platform.system()
    if system == 'Windows':
        return 'C:/Windows/Fonts/malgun.ttf'
    elif system == 'Darwin':
        return '/System/Library/Fonts/AppleGothic.ttf'
    elif system == 'Linux':
        # ë¦¬ëˆ…ìŠ¤ ì„œë²„ ê¸°ë³¸ í°íŠ¸ ê²½ë¡œ (ì„¤ì¹˜ë˜ì–´ ìˆì„ ê²½ìš°)
        linux_font = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        if os.path.exists(linux_font):
            return linux_font
    return None
def plotChart(count_dict, container):
    try:
        img_path = './resources/background_0.png'
        my_mask = np.array(Image.open(img_path)) if os.path.exists(img_path) else None
        wc = WordCloud(
            font_path=get_font_path(),
            background_color='white',
            width=500, height=500,
            max_words=300,
            mask=my_mask
        )
        # count_dictì—ëŠ” ì´ë¯¸ 'ê¸°ì‚¬ ë°œìƒ ìˆ˜'ê°€ ê°’ìœ¼ë¡œ ë“¤ì–´ìˆìŒ
        wc.generate_from_frequencies(count_dict)
        fig, ax = plt.subplots(figsize=(10, 10))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis("off")
        container.pyplot(fig)
    except Exception as e:
        container.error(f"ì‹œê°í™” ì˜¤ë¥˜: {e}")

def load_lottie_local(filepath):
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except: return None

def render_header():
    col1, col2, col3 = st.columns([1, 4, 1], vertical_alignment="center")
    with col1:
        lottie_path = "./resources/header_logo.json"
        lottie_json = load_lottie_local(lottie_path)
        if lottie_json: st_lottie(lottie_json, speed=1, width=120, height=120, key="main_logo")
        else: st.markdown("### ğŸ”")
    with col2:
        st.markdown("<h1 style='text-align: center;'>ğŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ ì‹œê°í™”</h1>", unsafe_allow_html=True)
    with col3:
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.clear(); st.rerun()

# --- [3. ë©”ì¸ ë¡œì§] ---
if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False
if 'analysis_step' not in st.session_state: st.session_state['analysis_step'] = False
if not st.session_state['logged_in']:
    st.title("ğŸ”‘ Naver API ì¸ì¦")
    
    col1, col2 = st.columns(2)
    with col1:
        c_id = st.text_input("Client ID")
    with col2:
        c_pw = st.text_input("Client Secret", type="password")
    
    if st.button("âœ… ì‹œì‘", use_container_width=True):
        if c_id and c_pw:
            # ì„ì‹œë¡œ ì„¸ì…˜ì— ì €ì¥í•´ë³´ê³  í…ŒìŠ¤íŠ¸ í˜¸ì¶œ
            st.session_state['client_id'] = c_id
            st.session_state['client_secret'] = c_pw
            
            # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ (ë‹¨ì–´ í•˜ë‚˜ë¡œ ìœ íš¨ì„± í™•ì¸)
            test_res = get_naver_news("í…ŒìŠ¤íŠ¸", 1, 1)
            
            if test_res is not None: # ì„±ê³µ ì‹œ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¼ì§€ë¼ë„ Noneì´ ì•„ë‹ˆë©´ í‚¤ëŠ” ì •ìƒ)
                st.session_state['logged_in'] = True
                st.success("ì¸ì¦ ì„±ê³µ!")
                st.rerun()
            else:
                # ì—ëŸ¬ ë©”ì‹œì§€ëŠ” get_naver_news ì•ˆì—ì„œ st.errorë¡œ ì¶œë ¥ë¨
                st.session_state['client_id'] = None
                st.session_state['client_secret'] = None
        else:
            st.warning("IDì™€ Secretì„ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
else:
    render_header()
    
    with st.expander("ğŸš« ë¶ˆìš©ì–´ ê´€ë¦¬"):
        saved_stops = load_user_stopwords()
        if saved_stops:
            st.write(f"ì´ {len(saved_stops)}ê°œ ì €ì¥ë¨")
            
            col1, col2= st.columns([4, 1])
            with col1: 
                
                to_del = st.multiselect(
                    "ì‚­ì œí•  ë‹¨ì–´ ì„ íƒ", # ë‚´ë¶€ì ìœ¼ë¡œ í•„ìš”í•œ ì´ë¦„
                    options=sorted(list(saved_stops)),
                    label_visibility="collapsed" # ë ˆì´ë¸”ì„ ì™„ì „íˆ ì œê±°í•˜ê³  ê³µê°„ë„ ì•ˆ ì°¨ì§€í•¨
                )
            with col2:
                if st.button("ë‹¨ì–´ ì‚­ì œ"):
                    save_user_stopwords(saved_stops - set(to_del)); st.rerun()
        else: st.info("ì €ì¥ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with st.form(key='search_form'):
        
        sfcol1, sfcol2, sfcol3 = st.columns([3, 2, 2])
        with sfcol1:
            search_keyword = st.text_input("ë¶„ì„ í‚¤ì›Œë“œ")
        with sfcol2: 
            m_amount = st.slider('ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜ (m)', 100, 800, 100, 100)
        with sfcol3:
            n_amount = st.slider('ê¸°ì‚¬ë‹¹ ìˆ˜ì§‘í•  í•µì‹¬ ë‹¨ì–´ ìˆ˜ (n)', 30, 300, 50)
        
        if st.form_submit_button("ë¶„ì„ ì‹œì‘"):
            if search_keyword:
                my_tokenizer = getTokenizer()
                items = []
                for i in range(m_amount // 100):
                    items.extend(get_naver_news(search_keyword, 100, (i*100)+1))
                
                if items:
                    total_stats = {} # {ë‹¨ì–´: [ê¸°ì‚¬ë°œìƒìˆ˜, ì´ì–¸ê¸‰íšŸìˆ˜]}
                    news_data_list = []
                    saved_stops = load_user_stopwords()
                    pbar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, item in enumerate(items):
                        news_data_list.append({'ë‚ ì§œ': item['pubDate'], 'ì œëª©': cleanHtml(item['title']), 'ë§í¬': item['link']})
                        if 'n.news.naver.com' in item['link']:
                            try:
                                res = rq.get(item['link'], headers={'User-Agent':'Mozilla/5.0'}, timeout=5)
                                news_tag = BeautifulSoup(res.text, 'html.parser').select_one('#dic_area')
                                if news_tag:
                                    txt = cleanText(news_tag.text)
                                    tokens = [t[0] for t in my_tokenizer.tokenize(txt, flatten=False)]
                                    # 1. ë‹¨ì–´ ì¶”ì¶œ ë° ë‹¨ì–´ì¥ í•„í„°ë§
                                    words = [t for t in tokens if 2 <= len(t) <= 10 and t not in saved_stops]
                                    if words:
                                        full_counts = pd.Series(words).value_counts()
                                        # 2. ìƒìœ„ n_amountê°œ ì„ ì •
                                        top_n = full_counts.head(n_amount)
                                        
                                        # 3. ë“€ì–¼ ì¹´ìš´íŒ… (ì´ì§„ ê°€ì¤‘ì¹˜ + ì‹¤ì œ ë¹ˆë„)
                                        for word, count in top_n.items():
                                            if word not in total_stats:
                                                total_stats[word] = [0, 0]
                                            total_stats[word][0] += 1      # ê¸°ì‚¬ ë°œìƒ ìˆ˜ (Binary)
                                            total_stats[word][1] += count  # ì´ ì–¸ê¸‰ íšŸìˆ˜ (Raw Frequency)
                            except: continue
                        pbar.progress((idx + 1) / len(items))
                        status_text.text(f"ê¸°ì‚¬ ë¶„ì„ ì¤‘... ({idx+1}/{len(items)})")
                    
                    if total_stats:
                        # 4. ì •ë ¬: 1ìˆœìœ„ ê¸°ì‚¬ìˆ˜(x[1][0]), 2ìˆœìœ„ ì´ë¹ˆë„(x[1][1])
                        sorted_stats = dict(sorted(total_stats.items(), key=lambda x: (x[1][0], x[1][1]), reverse=True))
                        st.session_state.update({
                            'total_stats': sorted_stats,
                            'current_keyword': search_keyword,
                            'current_n': n_amount,
                            'news_items': news_data_list,
                            'analysis_step': True
                        })
                        if 'display_dict' in st.session_state: del st.session_state['display_dict']
                    else: st.error("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if st.session_state.get('analysis_step') and 'total_stats' in st.session_state:
        full_dict = st.session_state['total_stats']
        display_limit = st.session_state.get('current_n', 50)
        top_words = list(full_dict.keys())[:display_limit]
        saved_stops = load_user_stopwords()

        st.divider()
        st.subheader(f"ğŸ› ï¸ '{st.session_state['current_keyword']}' ê²°ê³¼ ì •ì œ")
        use_auto = st.toggle("ğŸ’¾ ì˜êµ¬ ì œì™¸ ë‹¨ì–´ì¥ ìë™ ì ìš©", value=True)
        default_sel = [w for w in top_words if w not in saved_stops] if use_auto else top_words
        selected = st.multiselect("í¬í•¨í•  ë‹¨ì–´ ì„ íƒ:", options=top_words, default=default_sel)

        if st.button("âœ¨ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"):
            removed = set(top_words) - set(selected)
            if use_auto and removed:
                save_user_stopwords(saved_stops.union(removed))
                st.toast(f"{len(removed)}ê°œ ë‹¨ì–´ ì €ì¥ë¨")
            # ì›Œë“œí´ë¼ìš°ë“œìš©ìœ¼ë¡œëŠ” 'ê¸°ì‚¬ ë°œìƒ ìˆ˜'ë§Œ ì „ë‹¬
            st.session_state['display_dict'] = {k: full_dict[k][0] for k in selected}
            st.rerun()

        if 'display_dict' in st.session_state:
            st.divider()
            c1, c2 = st.columns([2, 1.5])
            with c1: plotChart(st.session_state['display_dict'], st)
            with c2: 
                st.write("### ğŸ“ˆ ê¸°ì‚¬ìˆ˜ & ì´ë¹ˆë„")
                # í…Œì´ë¸”ì—ëŠ” ë‘ ìˆ˜ì¹˜ë¥¼ ëª¨ë‘ í‘œì‹œí•˜ì—¬ ì •ë ¬ ê¸°ì¤€ í™•ì¸ ê°€ëŠ¥í•˜ê²Œ í•¨
                stat_data = [
                    {'ë‹¨ì–´': k, 'ë“±ì¥ ê¸°ì‚¬ ìˆ˜': full_dict[k][0], 'ì´ ì–¸ê¸‰ íšŸìˆ˜': full_dict[k][1]} 
                    for k in st.session_state['display_dict'].keys()
                ]
                st.dataframe(pd.DataFrame(stat_data), use_container_width=True)

            # --- [ì¶”ê°€ëœ ì„¹ì…˜: ìŠ¤í¬ë© ê¸°ì‚¬ ëª©ë¡] ---
            st.divider()
            st.subheader("ğŸ“° ë¶„ì„ëœ ê¸°ì‚¬ ì›ë¬¸ ëª©ë¡")
            
            if 'news_items' in st.session_state and st.session_state['news_items']:
                # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                df_news = pd.DataFrame(st.session_state['news_items'])
                
                # ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³´ì—¬ì£¼ê¸° (ì˜µì…˜)
                # ë°ì´í„°í”„ë ˆì„ ë‚´ì—ì„œ ë§í¬ë¥¼ ì§ì ‘ í´ë¦­í•˜ê²Œ í•˜ë ¤ë©´ st.column_configë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                st.dataframe(
                    df_news,
                    column_config={
                        "ë§í¬": st.column_config.LinkColumn("ê¸°ì‚¬ ë§í¬"),
                        "ë‚ ì§œ": st.column_config.DateColumn("ë°œí–‰ì¼", format="YYYY-MM-DD")
                    },
                    use_container_width=True,
                    hide_index=True
                )
            else:
                st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")