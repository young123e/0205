import streamlit as st
import re 
import urllib.request
import urllib.parse
import requests as rq
from bs4 import BeautifulSoup
import json
import pickle
import numpy as np
import pandas as pd
from PIL import Image
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from streamlit_lottie import st_lottie
import platform
import os
import urllib.error
from typing import Dict, List, Optional, Tuple

# --- [1. ì„¤ì • ë° ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜] ---
st.set_page_config(page_title="ğŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ ì‹œê°í™”")

STOPWORDS_FILE = './resources/user_stopwords.json'

def load_user_stopwords():
    if os.path.exists(STOPWORDS_FILE):
        try:
            with open(STOPWORDS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except: return set()
    return set()

def save_user_stopwords(stopwords_set):
    if not os.path.exists('./resources'):
        os.makedirs('./resources')
    with open(STOPWORDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(sorted(stopwords_set)), f, ensure_ascii=False)

def get_naver_news(keyword, display, start):
    client_id = st.session_state.get('client_id')
    client_secret = st.session_state.get('client_secret')
    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display={display}&start={start}"
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            return json.loads(response.read().decode('utf-8'))['items']
    except urllib.error.HTTPError as e:
        if e.code == 401:
            st.error("âŒ API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. Client IDì™€ Secretì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif e.code == 403:
            st.error("âŒ API ê¶Œí•œì´ ì—†ê±°ë‚˜ í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error(f"âŒ API ì˜¤ë¥˜ ë°œìƒ: {e.code}")
        return None # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  Noneì„ ë°˜í™˜í•˜ì—¬ ì—ëŸ¬ì„ì„ í‘œì‹œ
    except Exception as e:
        st.error(f"âŒ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def cleanText(text):
    text = re.sub(r'\d|[a-zA-Z]|\W',' ', text)
    return re.sub(r'\s+',' ', text)

def cleanHtml(text):
    text = re.sub(r'<[^>]+>', '', text)
    for ent, char in [('&quot;', '"'), ('&apos;', "'"), ('&amp;', '&'), ('&lt;', '<'), ('&gt;', '>')]:
        text = text.replace(ent, char)
    return text

@st.cache_resource
def getTokenizer():
    try:
        with open('./resources/my_tokenizer3.model','rb') as f:
            return pickle.load(f)
    except: return None

def get_font_path() -> Optional[str]:
    # 1. ë¨¼ì € resources í´ë”ì— ì§ì ‘ ì—…ë¡œë“œí•œ í°íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
    local_font = './resources/NanumGothic-Regular.ttf' # íŒŒì¼ëª…ì— ë§ì¶° ìˆ˜ì •
    if os.path.exists(local_font):
        return local_font
    
    # 2. ì—†ì„ ê²½ìš° ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„ (ê¸°ì¡´ ë¡œì§)
    system = platform.system()
    if system == 'Windows':
        return 'C:/Windows/Fonts/malgun.ttf'
    elif system == 'Darwin':
        return '/System/Library/Fonts/AppleGothic.ttf'
    elif system == 'Linux':
        # ë¦¬ëˆ…ìŠ¤ ì„œë²„ ê¸°ë³¸ í°íŠ¸ ê²½ë¡œ (ì„¤ì¹˜ë˜ì–´ ìˆì„ ê²½ìš°)
        linux_font = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        if os.path.exists(linux_font):
            return linux_font
    return None
def plotChart(count_dict, container):
    try:
        img_path = './resources/background_0.png'
        my_mask = np.array(Image.open(img_path)) if os.path.exists(img_path) else None
        wc = WordCloud(
            font_path=get_font_path(),
            background_color='white',
            width=500, height=500,
            max_words=300,
            mask=my_mask
        )
        # count_dictì—ëŠ” ì´ë¯¸ 'ê¸°ì‚¬ ë°œìƒ ìˆ˜'ê°€ ê°’ìœ¼ë¡œ ë“¤ì–´ìˆìŒ
        wc.generate_from_frequencies(count_dict)
        fig, ax = plt.subplots(figsize=(10, 10))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis("off")
        container.pyplot(fig)
    except Exception as e:
        container.error(f"ì‹œê°í™” ì˜¤ë¥˜: {e}")

def load_lottie_local(filepath):
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except: return None

def render_header():
    col1, col2, col3 = st.columns([1, 4, 1], vertical_alignment="center")
    with col1:
        lottie_path = "./resources/header_logo.json"
        lottie_json = load_lottie_local(lottie_path)
        if lottie_json: st_lottie(lottie_json, speed=1, width=120, height=120, key="main_logo")
        else: st.markdown("### ğŸ”")
    with col2:
        st.markdown("<h1 style='text-align: center;'>ğŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ ì‹œê°í™”</h1>", unsafe_allow_html=True)
    with col3:
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.clear(); st.rerun()

# --- [3. ë©”ì¸ ë¡œì§] ---
if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False
if 'analysis_step' not in st.session_state: st.session_state['analysis_step'] = False
if not st.session_state['logged_in']:
    st.title("ğŸ”‘ Naver API ì¸ì¦")
    
    # 1. ì‚¬ìš©ì ì´ë¦„(í‚¤) ì…ë ¥ ë°›ê¸°
    user_name = st.text_input("ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ë¯¸ë¦¬ ë“±ë¡ëœ ì´ë¦„)")
    
    if st.button("âœ… ì‹œì‘", use_container_width=True):
        if user_name:
            try:
                # 2. Secretsì—ì„œ ì…ë ¥í•œ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                # st.secrets["USER_ABC"] í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ì— ì ‘ê·¼
                user_info = st.secrets.get(user_name)
                
                if user_info:
                    c_id = user_info["CLIENT_ID"]
                    c_pw = user_info["CLIENT_SECRET"]
                    
                    # ì„¸ì…˜ì— ì €ì¥ ë° í…ŒìŠ¤íŠ¸
                    st.session_state['client_id'] = c_id
                    st.session_state['client_secret'] = c_pw
                    
                    # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ (ì‘ì„±í•˜ì‹  í•¨ìˆ˜ ì‚¬ìš©)
                    test_res = get_naver_news("í…ŒìŠ¤íŠ¸", 1, 1)
                    
                    if test_res is not None:
                        st.session_state['logged_in'] = True
                        st.success(f"{user_name}ë‹˜, ì¸ì¦ ì„±ê³µ!")
                        st.rerun()
                else:
                    st.error("ë“±ë¡ë˜ì§€ ì•Šì€ ì‚¬ìš©ì ì´ë¦„ì…ë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
else:
    render_header()
    


    with st.form(key='search_form'):
        
        sfcol1, sfcol2, sfcol3 = st.columns([3, 2, 2])
        with sfcol1:
            search_keyword = st.text_input("ë¶„ì„ í‚¤ì›Œë“œ")
        with sfcol2: 
            m_amount = st.slider('ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜ (m)', 100, 800, 100, 100)
        with sfcol3:
            n_amount = st.slider('ê¸°ì‚¬ë‹¹ ìˆ˜ì§‘í•  í•µì‹¬ ë‹¨ì–´ ìˆ˜ (n)', 30, 300, 50)
        
        if st.form_submit_button("ë¶„ì„ ì‹œì‘"):
            if search_keyword:
                my_tokenizer = getTokenizer()
                items = []
                for i in range(m_amount // 100):
                    items.extend(get_naver_news(search_keyword, 100, (i*100)+1))
                
                if items:
                    total_stats = {} # {ë‹¨ì–´: [ê¸°ì‚¬ë°œìƒìˆ˜, ì´ì–¸ê¸‰íšŸìˆ˜]}
                    news_data_list = []
                    saved_stops = load_user_stopwords()
                    pbar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, item in enumerate(items):
                        news_data_list.append({'ë‚ ì§œ': item['pubDate'], 'ì œëª©': cleanHtml(item['title']), 'ë§í¬': item['link']})
                        if 'n.news.naver.com' in item['link']:
                            try:
                                res = rq.get(item['link'], headers={'User-Agent':'Mozilla/5.0'}, timeout=5)
                                news_tag = BeautifulSoup(res.text, 'html.parser').select_one('#dic_area')
                                if news_tag:
                                    txt = cleanText(news_tag.text)
                                    tokens = [t[0] for t in my_tokenizer.tokenize(txt, flatten=False)]
                                    # 1. ë‹¨ì–´ ì¶”ì¶œ ë° ë‹¨ì–´ì¥ í•„í„°ë§
                                    words = [t for t in tokens if 2 <= len(t) <= 10 and t not in saved_stops]
                                    if words:
                                        full_counts = pd.Series(words).value_counts()
                                        # 2. ìƒìœ„ n_amountê°œ ì„ ì •
                                        top_n = full_counts.head(n_amount)
                                        
                                        # 3. ë“€ì–¼ ì¹´ìš´íŒ… (ì´ì§„ ê°€ì¤‘ì¹˜ + ì‹¤ì œ ë¹ˆë„)
                                        for word, count in top_n.items():
                                            if word not in total_stats:
                                                total_stats[word] = [0, 0]
                                            total_stats[word][0] += 1      # ê¸°ì‚¬ ë°œìƒ ìˆ˜ (Binary)
                                            total_stats[word][1] += count  # ì´ ì–¸ê¸‰ íšŸìˆ˜ (Raw Frequency)
                            except: continue
                        pbar.progress((idx + 1) / len(items))
                        status_text.text(f"ê¸°ì‚¬ ë¶„ì„ ì¤‘... ({idx+1}/{len(items)})")
                    
                    if total_stats:
                        # 4. ì •ë ¬: 1ìˆœìœ„ ê¸°ì‚¬ìˆ˜(x[1][0]), 2ìˆœìœ„ ì´ë¹ˆë„(x[1][1])
                        sorted_stats = dict(sorted(total_stats.items(), key=lambda x: (x[1][0], x[1][1]), reverse=True))
                        st.session_state.update({
                            'total_stats': sorted_stats,
                            'current_keyword': search_keyword,
                            'current_n': n_amount,
                            'news_items': news_data_list,
                            'analysis_step': True
                        })
                        if 'display_dict' in st.session_state: del st.session_state['display_dict']
                    else: st.error("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if st.session_state.get('analysis_step') and 'total_stats' in st.session_state:
        full_dict = st.session_state['total_stats']
        display_limit = st.session_state.get('current_n', 50)
        top_words = list(full_dict.keys())[:display_limit]
        saved_stops = load_user_stopwords()

        st.divider()
        st.subheader(f"ğŸ› ï¸ '{st.session_state['current_keyword']}' í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼")
        
        use_auto = st.toggle("ğŸ’¾ ì œì™¸ ë‹¨ì–´ ì ìš©", value=True)
        default_sel = [w for w in top_words if w not in saved_stops] if use_auto else top_words
        
        selected = st.multiselect("ë‹¨ì–´ ì„ íƒ:", options=top_words, default=default_sel)
        with st.expander("ğŸš« ë¶ˆìš©ì–´ ê´€ë¦¬"):
            saved_stops = load_user_stopwords()
            
            # 1. ë‹¨ì–´ ì¶”ê°€ ì„¹ì…˜ (ìƒˆë¡œ ë¶„ì„ëœ ë‹¨ì–´ë“¤ì„ ë¯¸ë¦¬ ì„¸íŒ…)
            st.markdown("#### â• ë‹¨ì–´ ì¶”ê°€")
            col_add1, col_add2 = st.columns([4, 1])
            with col_add1:
                # í˜„ì¬ ë¶„ì„ ê²°ê³¼(top_words) ì¤‘ ì•„ì§ ë¶ˆìš©ì–´ì— ë“±ë¡ë˜ì§€ ì•Šì€ ë‹¨ì–´ë“¤ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì œì•ˆ
                suggested_new_stops = [w for w in top_words if w not in saved_stops]
                to_add = st.multiselect(
                    "ë¶ˆìš©ì–´ë¡œ ì¶”ê°€í•  ë‹¨ì–´ ì„ íƒ",
                    options=top_words, 
                    default=[], # í˜¹ì€ suggested_new_stopsë¥¼ ë„£ìœ¼ë©´ ë¶„ì„ëœ ëª¨ë“  ë‹¨ì–´ê°€ ì„¸íŒ…ë©ë‹ˆë‹¤.
                    key="add_stop_words",
                    help="ë¶„ì„ ê²°ê³¼ì—ì„œ ì œì™¸í•˜ê³  ì‹¶ì€ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”."
                )
            with col_add2:
                if st.button("ë‹¨ì–´ ì¶”ê°€", use_container_width=True):
                    if to_add:
                        save_user_stopwords(saved_stops.union(set(to_add)))
                        st.toast(f"{len(to_add)}ê°œ ë‹¨ì–´ê°€ ë¶ˆìš©ì–´ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    else:
                        st.warning("ë‹¨ì–´ê°€ ë¶„ì„ ê²°ê³¼ì— ì—†ìŠµë‹ˆë‹¤.")

            st.divider()

            # 2. ë‹¨ì–´ ì‚­ì œ ì„¹ì…˜ (ê¸°ì¡´ì— ì €ì¥ëœ ë¶ˆìš©ì–´ ê´€ë¦¬)
            st.markdown("#### â– ë‹¨ì–´ ì°¨ë‹¨ í•´ì œ")
            if saved_stops:
                st.write(f"í˜„ì¬ ì´ {len(saved_stops)}ê°œì˜ ë‹¨ì–´ê°€ ì°¨ë‹¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                col_del1, col_del2 = st.columns([4, 1])
                with col_del1:
                    to_del = st.multiselect(
                        "ì‚­ì œí•  ë‹¨ì–´ ì„ íƒ",
                        options=sorted(list(saved_stops)),
                        label_visibility="collapsed",
                        key="del_stop_words"
                    )
                with col_del2:
                    if st.button("ì°¨ë‹¨ í•´ì œ", use_container_width=True):
                        if to_del:
                            save_user_stopwords(saved_stops - set(to_del))
                            st.toast(f"{len(to_del)}ê°œ ë‹¨ì–´ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            st.warning("ì„ íƒëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("í˜„ì¬ ì €ì¥ëœ ë¶ˆìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.divider()

        if st.button("âœ¨ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"):
            removed = set(top_words) - set(selected)
            if use_auto and removed:
                save_user_stopwords(saved_stops.union(removed))
                st.toast(f"{len(removed)}ê°œ ë‹¨ì–´ ì €ì¥ë¨")
            # ì›Œë“œí´ë¼ìš°ë“œìš©ìœ¼ë¡œëŠ” 'ê¸°ì‚¬ ë°œìƒ ìˆ˜'ë§Œ ì „ë‹¬
            st.session_state['display_dict'] = {k: full_dict[k][0] for k in selected}
            st.rerun()

        if 'display_dict' in st.session_state:
            
            c1, c2 = st.columns([2, 1.5])
            with c1: plotChart(st.session_state['display_dict'], st)
            with c2: 
                st.write("### ğŸ“ˆ ê¸°ì‚¬ìˆ˜ & ì´ë¹ˆë„")
                # í…Œì´ë¸”ì—ëŠ” ë‘ ìˆ˜ì¹˜ë¥¼ ëª¨ë‘ í‘œì‹œí•˜ì—¬ ì •ë ¬ ê¸°ì¤€ í™•ì¸ ê°€ëŠ¥í•˜ê²Œ í•¨
                stat_data = [
                    {'ë‹¨ì–´': k, 'ë“±ì¥ ê¸°ì‚¬ ìˆ˜': full_dict[k][0], 'ì´ ì–¸ê¸‰ íšŸìˆ˜': full_dict[k][1]} 
                    for k in st.session_state['display_dict'].keys()
                ]
                st.dataframe(pd.DataFrame(stat_data), use_container_width=True)
            
                

            # --- [ì¶”ê°€ëœ ì„¹ì…˜: ìŠ¤í¬ë© ê¸°ì‚¬ ëª©ë¡] ---
            st.divider()
            st.subheader("ğŸ“° ë¶„ì„ëœ ê¸°ì‚¬ ì›ë¬¸ ëª©ë¡")
            
            if 'news_items' in st.session_state and st.session_state['news_items']:
                # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                df_news = pd.DataFrame(st.session_state['news_items'])
                
                # ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³´ì—¬ì£¼ê¸° (ì˜µì…˜)
                # ë°ì´í„°í”„ë ˆì„ ë‚´ì—ì„œ ë§í¬ë¥¼ ì§ì ‘ í´ë¦­í•˜ê²Œ í•˜ë ¤ë©´ st.column_configë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                st.dataframe(
                    df_news,
                    column_config={
                        "ë§í¬": st.column_config.LinkColumn("ê¸°ì‚¬ ë§í¬"),
                        "ë‚ ì§œ": st.column_config.DateColumn("ë°œí–‰ì¼", format="YYYY-MM-DD")
                    },
                    use_container_width=True,
                    hide_index=True
                )
            else:
                st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")